{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "anOObdcawtgs"
      },
      "source": [
        "# *PROJECT TASK*\n",
        "\n",
        "The goal of practical project is to explain, using all techniques explained in class, the ML\n",
        "models assigned.\n",
        "At least each team must explain 2 ML models (a.k.a. compulsory models). Additionally,\n",
        "the team can build and explain a third model (a.k.a. extra model).\n",
        "\n",
        "The Practical Project will consist of:\n",
        "\n",
        "- Python 2 or 3 notebooks: ipynb file for each model.\n",
        "- Dataset: csv file or online load hardcoded.\n",
        "\n",
        "Each notebook must include:\n",
        "\n",
        "- Markdown use:\n",
        "    - Sections and subsections numbered (using #, ##, etc.)\n",
        "    - Concise and clear descriptions of the decisions made\n",
        "    - Concise and clear conclusions of the explanations obtained.\n",
        "\n",
        "- The code must be clear and must include comments.\n",
        "- The notebook must include 3 sections (you can add subsections):\n",
        "\n",
        "1. Dataset load and preparation\n",
        "2. ML model training\n",
        "3. ML explanation\n",
        "\n",
        "The ML explanation, section 3, is the most important part of the project. Here you should\n",
        "cover:\n",
        "\n",
        "- Use any explanation method useful that you’ve seen on class.\n",
        "- Provide individual explanations of instance. Not just plots, but the conclusions\n",
        "you can make.\n",
        "- Provide global explanations of the ML model. Not just plots, but the conclusions\n",
        "you can make."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcaXb1EIwtgt"
      },
      "source": [
        "# Machine Learning Explicable. Explicación de un MODEL_TYPE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW2LYM2Awtgu"
      },
      "source": [
        "## 0. Requerimientos y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "orB9sfsDwtgu"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from skopt import BayesSearchCV\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sklearn.impute as impute\n",
        "\n",
        "from sklearn import metrics\n",
        "from scipy import stats\n",
        "\n",
        "# Regresión\n",
        "\n",
        "# Preprocesamiento\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Desbalanceo\n",
        "#from imblearn.over_sampling import SVMSMOTE, RandomOverSampler, ADASYN\n",
        "#from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
        "#from imblearn.ensemble import RUSBoostClassifier\n",
        "#from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Modelos de clasificación\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "\n",
        "# TODO: Explicabilidad: SHAP, LIME\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JMGO-coding/MLX_academic_performance.git\n",
        "!cd MLX_academic_performance/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1zAHZK7xozA",
        "outputId": "2de5d0a5-d9ea-47e1-ede5-c686611d7d08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLX_academic_performance'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 33 (delta 7), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 234.43 KiB | 1.17 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Añadir los directorio fuentes al path de Python\n",
        "sys.path.append('/content/MLX_academic_performance')\n",
        "sys.path.append('/content/MLX_academic_performance/src')\n",
        "\n",
        "# Verificar que se han añadido correctamente\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3V8bG0xxsfo",
        "outputId": "ed6bd356-b158-483b-f80c-55d3d81d986e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython', '/content/k_brazos_GGM', '/content/k_brazos_GGM/src', '/content/MLX_academic_performance', '/content/MLX_academic_performance/src']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pZxhyHX4wtgv"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_path=\"models/best_model_DT.pkl\"):\n",
        "    \"\"\"\n",
        "    Guarda un modelo un archivo pkl.\n",
        "    \"\"\"\n",
        "    joblib.dump(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GIAFSHvowtgv"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path=\"models/best_model_DT.pkl\"):\n",
        "    \"\"\"\n",
        "    Carga un modelo previamente guardado desde un archivo.\n",
        "    \"\"\"\n",
        "    return joblib.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQ84Zl8wtgv"
      },
      "source": [
        "## 1. Carga y preprocesamiento del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MBOf1Vlwtgw"
      },
      "source": [
        "### 1.1. Primeras visualizaciones y estadísticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ll7Y2D3Kwtgw"
      },
      "outputs": [],
      "source": [
        "# Fijamos la semilla y los directorios\n",
        "\n",
        "SEED = 2024\n",
        "directory = '../'\n",
        "plots_directory = directory + 'plots/'\n",
        "data_directory = directory + 'data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "vgtOdUxqwtgx",
        "outputId": "8be921cc-fec3-48d4-bbfe-2fdaeee04e73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f236f0733417>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data.csv'"
          ]
        }
      ],
      "source": [
        "# Lectura del Dataset y primera visualziación\n",
        "\n",
        "data_file = 'data.csv'\n",
        "data_path = data_directory + data_file\n",
        "df= pd.read_csv(data_path, sep=';')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oikdVla6wtgx"
      },
      "outputs": [],
      "source": [
        "df.info()   # Conteo de no-nulos y data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU6r0eoywtgy"
      },
      "outputs": [],
      "source": [
        "df.describe()   # Estadísticos básicos sobre los features numéricos del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8lyILgDwtgy"
      },
      "source": [
        "El dataset no contiene valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R65dH5wwtgy"
      },
      "outputs": [],
      "source": [
        "# Variables según su tipo\n",
        "\n",
        "categorical_features = ['Marital status', 'Application mode', 'Course', 'Nacionality', 'Mother\\'s occupation', 'Father\\'s occupation']\n",
        "\n",
        "numerical_features = ['Application order', 'Previous qualification', 'Previous qualification (grade)',\n",
        "                      'Mother\\'s qualification',  'Father\\'s qualification', 'Admission grade', 'Age at enrollment',\n",
        "                      'Curricular units 1st sem (credited)',  'Curricular units 1st sem (enrolled)',  'Curricular units 1st sem (evaluations)',\n",
        "                      'Curricular units 1st sem (approved)', 'Curricular units 1st sem (grade)',  'Curricular units 1st sem (without evaluations)',\n",
        "                      'Curricular units 2st sem (credited)',  'Curricular units 2st sem (enrolled)',  'Curricular units 2st sem (evaluations)',\n",
        "                      'Curricular units 2st sem (approved)', 'Curricular units 2st sem (grade)',  'Curricular units 2st sem (without evaluations)',\n",
        "                      'Unemployment rate', 'Inflation rate', 'GDP'\n",
        "                    ]\n",
        "binary_features = ['Daytime/evening attendance\\t', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', 'Gender',\n",
        "                   'Scholarship holder', 'International']\n",
        "\n",
        "target_feature = 'Target' # Categorical 3 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-DO7XCBSxMFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ikllik6wtgz"
      },
      "outputs": [],
      "source": [
        "# Histograma variables categóricas\n",
        "\n",
        "for feature in [target_feature] + categorical_features + binary_features:\n",
        "    sns.countplot(y=feature, data=df)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lw1Ibh1wtgz"
      },
      "source": [
        "### 1.2. partición de los datos en *Train* y *Test*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3G_5Xyiwtgz"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Target'])\n",
        "y = df['Target']\n",
        "test_size = 0.1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqhDp1J_wtgz"
      },
      "outputs": [],
      "source": [
        "# Ver distribución de las variables predictoras numéricas (no la objetivo) en diagrama de cajas\n",
        "plt.figure(figsize=(20, 20))\n",
        "# Boxplot of dftrain except SalePrice\n",
        "dftrain.boxplot(column=list(numerical_features), rot=90)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvdQRuKSwtgz"
      },
      "source": [
        "## 2. Entrenamiento del modelo (Decision Tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jgg03V7wtg0"
      },
      "outputs": [],
      "source": [
        "# Ejecutamos un Grid search y nos quedamos con el modelod e mejores hiperparámetros\n",
        "\n",
        "param_grid = {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_depth': [3, 5, 7, 10, 15, 20, 25, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 5]\n",
        "    }\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=SEED)\n",
        "grid_search = GridSearchCV(dt, param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"F1-score en test:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMy7lSZ7wtg0"
      },
      "source": [
        "## 3. Explicación del modelo"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}